# -*- coding: utf-8 -*-
"""projet7_dashboard.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tGnv9UXZsGa3gKnsYcjoi6iqHziTG5-t
"""

# Import librairies
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import xgboost as xgb
import pickle
import matplotlib
import matplotlib.pyplot as plt
import shap
from sklearn import model_selection
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import f1_score, matthews_corrcoef
from sklearn.metrics import plot_roc_curve
from matplotlib.colors import LinearSegmentedColormap
matplotlib.use('Agg')
st.set_option('deprecation.showPyplotGlobalUse', False)



# Load model
#loaded_model = pickle.load(open('/content/gdrive/My Drive/Colab Notebooks/Projet 7/xgbcl.dat', 'rb'))
loaded_model = pickle.load(open('xgbcl.dat', 'rb'))

# Load data
#loaded_data = pickle.load(open('/content/gdrive/My Drive/Colab Notebooks/Projet 7/data_credit_risk.dat', 'rb'))
loaded_data = pickle.load(open('data_credit_risk.dat', 'rb'))



#"""Create a dashboard"""


def main():
    st.title('Déterminer les variables les plus importantes pour l\'acceptation d\'un crédit dans le "Home Credit Default Risk" data set')
    st.subheader('Réalisé par: Hortense Monnard')
    

    @st.cache()
    def load_data():
        data = loaded_data.copy()
        return data
    
    # Create a text element and let the reader know the data is loading.
    data_load_state = st.text('Les données chargent...')
    # Load the data into the dataframe.
    data = load_data()
    # Notify the reader that the data was successfully loaded.
    data_load_state.text('Les données sont chargées!')

    st.title('Créer un dataframe à partir des données originales')
    
    @st.cache()
    def load_dataframe():
        Df = pd.DataFrame(data['data'], columns=data['feature_names'])
        Df['TARGET'] = data['target']
        return Df

    # Create a text element and let the reader know the dataframe has been created.
    dataframe_load_state = st.text('Le dataframe est créé!')
    # Load the data into the dataframe.
    Df = load_dataframe()
    # Notify the reader that the data was successfully loaded.
    dataframe_load_state.text('Les données sont chargées dans le dataframe!')

    # Make the IDD_CURR the index
    Df_features_only = Df.copy()
    Df_features_only.set_index('IDD_CURR', inplace=True)

    # Print the top 5 of the created Dataframe
    st.write('Ci-dessous sont affichées les 5 premières lignes du dataframe')
    st.write(Df_features_only.head(5))
    
    # Create test and training set
    x = Df_features_only.loc[:, Df_features_only.columns != 'TARGET'].values
    y = Df_features_only.loc[:, Df_features_only.columns == 'TARGET'].values
    X_train, X_test, y_train, y_test = model_selection.train_test_split(x,
                                                        y, 
                                                        test_size = 0.25, 
                                                        random_state=34)
   
    # Building the dashboard on XGBoost model:
    st.title('Modélisation du dataset "Home Credit Default Risk" avec XGBoostClassifier')

    # Loading the tuned XGBoost model
    #loaded_model = pickle.load(open("xgbcl.dat", "rb"))
    st.write('NB : Ce modèle a été entrainé au préalable et chargé ici pour des questions de performances')
    best_threshold = 0.092

    st.write('Le seuil de détermination optimal est de {:.3f}'.format(best_threshold))

    st.write('******************************************************')

    # Prediction with the new optimal threshold
    print('Prédictions avec le seuil optimisé')
        
    # Predict on training data
    y_train_pred_opt = (loaded_model.predict_proba(X_train)[:,1] >= best_threshold).astype(bool)

    # Prediction on test set
    y_test_pred_opt = (loaded_model.predict_proba(X_test)[:,1] >= best_threshold).astype(bool)

    # Metrics test set
    AUC = roc_auc_score(y_test, y_test_pred_opt)
    F1 = f1_score(y_test, y_test_pred_opt)
    MCC = matthews_corrcoef(y_test, y_test_pred_opt)
    var_stat_test = [AUC, F1, MCC]
    stat_test = pd.Series(var_stat_test)

    # Metrics train set
    AUC = roc_auc_score(y_train, y_train_pred_opt)
    F1 = f1_score(y_train, y_train_pred_opt) #average='binary' by default
    MCC = matthews_corrcoef(y_train, y_train_pred_opt)
    var_stat_train = [AUC, F1, MCC]
    stat_train = pd.Series(var_stat_train)

    # Create and print a table with the results
    var_stat = ['AUC', 'F1', 'MCC']
    stat = pd.Series(var_stat)
    df_stat = pd.DataFrame(stat, columns = ['Variable Stat'])
    df_stat_test = pd.DataFrame(stat_test, columns = ['XGBoost Test'])
    df_stat_train = pd.DataFrame(stat_train, columns = ['XGBoost Entrainement'])
    df_model = pd.concat([df_stat, df_stat_test, df_stat_train], axis=1)
    st.write(df_model)

    ## Confusion matrix
    cm_opt = confusion_matrix(y_test, y_test_pred_opt)

    # Define tp, fp, tn and fn
    tp = cm_opt[1,1]
    fp = cm_opt[0,1]
    tn = cm_opt[0,0]
    fn = cm_opt[1,0]

    st.write('Vrais Positifs = ', tp)
    st.write('Vrais Négatifs = ', tn)
    st.write('Faux Positifs = ', fp)
    st.write('Faux Négatifs = ', fn)

    st.write('******************************************************')

    # Specificity
    specificity = tn / float(tn + fp)
    st.write('Spécificité = ', specificity)

    # False Positive Rate
    if fp == 0:
        FP_rate = 0
    else:
        FP_rate = fp / float(tn + fp)
    st.write('Taux de Faux Positifs = ',FP_rate)

    st.write('******************************************************')

    # Print matrix
    st.title('Matrice de confusion')
    sns.heatmap(cm_opt, 
                xticklabels=['Prédit 0', 'Prédit 1'],
                yticklabels=['        Vrai 0', '        Vrai 1'],
                cmap="Blues",
                annot=True, 
                fmt='d'
                )
    st.pyplot(bbox_inches='tight')
    plt.clf()

    ## ROC curve
    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_opt)
    st.title('Courbe ROC')
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1)
    ax.plot(fpr, tpr)
    ax.set_xlabel('Taux de Faux Positifs (1 - Spécificité)')
    ax.set_ylabel('Taux de Vrai Positifs (Sensibilité)')
    st.pyplot(bbox_inches='tight')
    plt.clf()

    # Make the prediction the TARGET
    y_pred_opt = (loaded_model.predict_proba(x)[:,1] >= best_threshold).astype(bool)
    df_prediction = pd.DataFrame(y_pred_opt)
    df_prediction[0] = df_prediction[0]*1
    list_prediction = df_prediction[0].to_list()
    Df_features_only['TARGET'] = list_prediction


    st.title('Expliquer le modèle de classification à un public plus large')

    st.write('Le schéma ci-dessous illustre l\'importance de chaque variable. ') 
    explainer = shap.TreeExplainer(loaded_model)
    Df_features = Df_features_only.copy()
    X = Df_features.drop(['TARGET'], axis=1)
    shap_values = explainer.shap_values(X)

    # SHAP =SHapley Additive exPlanations
    st.title('Déterminer l\'importance des variables grâce à la méthode SHAP')
    shap.summary_plot(shap_values,
                      X,
                      plot_type="bar",
                      show=False)
    st.pyplot(bbox_inches='tight')
    plt.clf()
    
    st.write('Les valeurs SHAP peuvent être utilisées pour représenter la '
              'distribution respective de chaque variable en fonction de la cible.')
    
    st.title('Distribution totale des observations en fonction des valeurs Shap, '
              'avec des couleurs différentes en fonction de la valeur de la cible (TARGET)')
    shap.summary_plot(shap_values,
                      X,
                      show=False)
    st.pyplot(bbox_inches='tight')
    plt.clf()
    

    st.title('Observer la corrélation des différentes variables à la prédiction '
              'pour chaque client')

    # Use the index to define an ID_Client to look for the data of a client individualy 
    ID_Client = st.number_input('Entrer l\'identifiant client, IDD_CURR:',
                                min_value=int(X.index.min()),
                                max_value=int(X.index.max()),
                                format="%i",
                                )
    index_client = X.index==ID_Client

    shap.force_plot(explainer.expected_value, 
                    shap_values[index_client],
                    X.loc[ID_Client],
                    matplotlib=True,
                    show=False,
                    figsize=(16,5)
                    )
    st.pyplot(bbox_inches='tight',dpi=300,pad_inches=0)
    plt.clf()


    st.write('Prédiction de la demande de crédit pour le client :')
    st.write('Si TARGET=1, le crédit est accordé.')
    st.write('Si TARGET=0, le crédit n\'est pas accordé.')
    st.write(Df_features_only['TARGET'].loc[ID_Client])
    
    st.write('Dans le graphique ci-dessus, les différentes variables sont représentées.')
    st.write('Les variables en rouge augmentent la possibilité d\'une prédiction positive '
              'de l\acceptation d\'une demande de crédit. Les variables en bleu '
              'diminuent la possibilité d\'une prédiction positive')   
    st.write('La valeur SHAP est représentée par la longueur de la barre lui correspondant.'
             'Ci-dessous, il est possible de visualiser la valeur SHAP précise de chaque variable pour le client.')
    
    # Create a dataframe with shap_values and feature_names
    shap_table=pd.DataFrame(shap_values,
                            columns=data['feature_names'][1:]) 
    
    if st.button('Cliquer ici pour voir un rapport détaillé des valeurs SHAP par variables '):
        shap_table.index = Df['IDD_CURR']
        shap_table['TARGET'] = Df_features_only['TARGET']
        st.table(shap_table.loc[ID_Client])
        st.write('Comparaison aux autres clients en fonction de l\'acceptation de leur demande de crédit (TARGET=1 ou TARGET=0).')
        st.table(shap_table.groupby('TARGET').mean())
        st.write('Comparaison aux autres clients de manière générale.')
        st.table(shap_table.describe())

       
    st.write('Ce graphique et ces détails permettent de comprendre '
              'les motivations de la réponse à la demande de crédit.')
       

if __name__== '__main__':
    main()